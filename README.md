# ğŸ§® ML Algorithms: Step-by-Step Implementations

Step-by-step implementation of core Machine Learning algorithms with performance comparisons against sklearn implementations.

---

##  1. **Linear Regression**  
   - ğŸ“‰ Implemented both **analytical** and **numerical** solutions:  
     - Closed-form linear regression  
     - Powellâ€™s optimization method (scipy)  
   - ğŸ§ª Tested on synthetic 1D datasets (`make_regression`, noise=16)  
   - â±ï¸ Compared in terms of **accuracy** and **runtime**

---

##  2. **Linear Classification**  
   - ğŸ§¾ Analytical implementation with **Tikhonov regularization**  
   - ğŸ§ª Benchmarked against `RidgeClassifier` from sklearn  
   - â¤ï¸ Applied to **Cleveland Heart Disease** dataset:
     - Data preprocessing, outlier removal  
     - Statistical profiling and feature selection (manual vs automatic)  

---

##  3. **Logistic Regression**
   - âš™ï¸ Custom implementation using:
     - **Gradient Descent** (with learning rate tuning)
     - âœ¨ **Mini-Batch** optimization
     - ğŸ“‰ **Squared Gradients Sum** (AdaGrad-style)
   - ğŸ§ª Tested on synthetic datasets:
     - Binary classification
     - Multi-class scenarios

---

##  4. **SVM (Support Vector Machines)**
   - ğŸ”§ Three kernel implementations:
     - â– **Linear Kernel** (hard/soft margin)
     - ğŸ”¶ **Polynomial Kernel** (degree customization)
     - ğŸŒ **RBF Kernel** (gamma parameter tuning)
   - âš–ï¸ Benchmarking against sklearn's SVM:
     - Accuracy comparison
     - Training time analysis
   - ğŸ“Š Visualization of decision boundaries

---

##  5. **Decision Tree**
   - ğŸŒ¡ï¸ **Entropy Minimization** approach:
     - Recursive binary splitting
     - Pre-pruning parameters
   - ğŸ§ª Test scenarios:
     - Single-feature datasets
     - High-dimensional multi-class problems
   - ğŸ“‰ Comparison with sklearn's DecisionTreeClassifier

---

##  6. **Random Forest**
   - ğŸ—ï¸ Custom ensemble features:
     - Bagging with replacement
     - Feature subspace selection
     - Comparison with sklearn.ensemble.RandomForest

---

##  7. **Neural Network (Custom Implementation)**  
   - ğŸ§  Manually built **multi-layer feedforward neural network**
   - ğŸ“¦ Trained on **MNIST** with adjustable activation functions (e.g., ReLU, Sigmoid)  
   - ğŸ“ˆ Reports metrics after each epoch: **accuracy**, **sensitivity**, **specificity**  

---

## ğŸ‘¨â€ğŸ’» Author  
**PaweÅ‚ Marchel**  
If you find this project helpful, feel free to star â­ the repo or get in touch for collaboration.
