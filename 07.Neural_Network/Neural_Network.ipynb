{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oHVaZBoB1qWl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network\n",
        "\n",
        "Step-by-Step implementation of a neural network that will later be trained on the MNIST dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "oYanL4VbY4VI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class NeuralNetwork:\n",
        "\n",
        "- **init:** The constructor initializes an instance of the `NeuralNetwork` class with specified layer sizes and activation functions. By default, activations are set to sigmoid functions for all layers.\n",
        "\n",
        "- **initialize:** This method initializes the neural network parameters such as weights and biases, randomly sampling them from a normal distribution.\n",
        "\n",
        "- **forward:** Performs forward propagation for the input data `x`, calculating outputs at each layer using the current weights and biases.\n",
        "\n",
        "- **backward:** Executes backpropagation for input `x`, computing loss gradients for each network parameter to update weights and biases during training.\n",
        "\n",
        "- **optimize:** Updates the networkâ€™s weights and biases by applying gradient-based optimization to minimize the loss function.\n",
        "\n",
        "- **train:** Trains the neural network model on training data `x_train` and labels `y_train` for a specified number of epochs and batch size, using forward and backward propagation. At the end of each epoch, metrics such as accuracy, sensitivity, specificity, and execution time are displayed.\n"
      ],
      "metadata": {
        "id": "blEQBklBZYoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork():\n",
        "\n",
        "    def __init__(self, sizes, activations=None):\n",
        "        self.sizes = sizes\n",
        "        if activations is None:\n",
        "            activations = ['sigmoid'] * (len(sizes) - 1)\n",
        "\n",
        "        self.activations = []\n",
        "        self.activation_derivatives = []\n",
        "        for activation in activations:\n",
        "            if activation == 'relu':\n",
        "                self.activations.append(self.relu)\n",
        "                self.activation_derivatives.append(self.relu_derivative)\n",
        "            else:\n",
        "                self.activations.append(self.sigmoid)\n",
        "                self.activation_derivatives.append(self.sigmoid_derivative)\n",
        "\n",
        "        self.params = self.initialize()\n",
        "        self.cache = {}\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def relu_derivative(self, x):\n",
        "        return np.where(x <= 0, 0, 1)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
        "\n",
        "    def initialize(self):\n",
        "        params = {}\n",
        "        for i in range(1, len(self.sizes)):\n",
        "            input_size = self.sizes[i-1]\n",
        "            output_size = self.sizes[i]\n",
        "\n",
        "            params[f\"W{i}\"] = np.random.randn(output_size, input_size) * np.sqrt(1. / input_size)\n",
        "            params[f\"b{i}\"] = np.zeros((output_size, 1))\n",
        "\n",
        "        return params\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.cache[\"X\"] = x\n",
        "        self.cache[\"A0\"] = x.T\n",
        "        for i in range(1, len(self.sizes)):\n",
        "            z = np.dot(self.params[f\"W{i}\"], self.cache[f\"A{i-1}\"]) + self.params[f\"b{i}\"]\n",
        "            self.cache[f\"Z{i}\"] = z\n",
        "            if i == len(self.sizes) - 1:\n",
        "                self.cache[f\"A{i}\"] = self.sigmoid(z)\n",
        "            else:\n",
        "                self.cache[f\"A{i}\"] = self.activations[i-1](z)\n",
        "        return self.cache[f\"A{len(self.sizes)-1}\"]\n",
        "\n",
        "\n",
        "    def backward(self, y, output):\n",
        "        current_batch_size = y.shape[0]\n",
        "        grads = {}\n",
        "\n",
        "        Z = output - y.T\n",
        "        for i in range(len(self.sizes)-1, 0, -1):\n",
        "            if i == len(self.sizes) - 1:\n",
        "                W = (1. / current_batch_size) * np.dot(Z, self.cache[f\"A{i-1}\"].T)\n",
        "                b = (1. / current_batch_size) * np.sum(Z, axis=1, keepdims=True)\n",
        "            else:\n",
        "                Z = np.dot(self.params[f\"W{i+1}\"].T, Z) * self.activation_derivatives[i-1](self.cache[f\"Z{i}\"])\n",
        "                W = (1. / current_batch_size) * np.dot(Z, self.cache[f\"A{i-1}\"].T)\n",
        "                b = (1. / current_batch_size) * np.sum(Z, axis=1, keepdims=True)\n",
        "            grads[f\"W{i}\"] = W\n",
        "            grads[f\"b{i}\"] = b\n",
        "\n",
        "        self.grads = grads\n",
        "        return grads\n",
        "\n",
        "    def optimize(self, l_rate=0.1):\n",
        "        for key in self.params:\n",
        "            self.params[key] = self.params[key] - l_rate * self.grads[key]\n",
        "\n",
        "    def accuracy(self, y, output):\n",
        "        return np.mean(np.argmax(y, axis=-1) == np.argmax(output.T, axis=-1))\n",
        "\n",
        "    def confusion_matrix(self, x, y):\n",
        "        predictions = self.predict(x)\n",
        "        return confusion_matrix(np.argmax(y, axis=-1), predictions)\n",
        "\n",
        "    def sensitivity_specificity(self, confusion_matrix):\n",
        "        num_classes = confusion_matrix.shape[0]\n",
        "\n",
        "        if num_classes == 2:\n",
        "            true_positive = confusion_matrix[1, 1]\n",
        "            false_positive = confusion_matrix[0, 1]\n",
        "            false_negative = confusion_matrix[1, 0]\n",
        "            true_negative = confusion_matrix[0, 0]\n",
        "\n",
        "            sensitivity = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
        "            specificity = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0\n",
        "        else:\n",
        "            sensitivity = np.zeros(num_classes)\n",
        "            specificity = np.zeros(num_classes)\n",
        "\n",
        "            for i in range(num_classes):\n",
        "                true_positive = confusion_matrix[i, i]\n",
        "                false_positive = np.sum(confusion_matrix[:, i]) - true_positive\n",
        "                false_negative = np.sum(confusion_matrix[i, :]) - true_positive\n",
        "                true_negative = np.sum(confusion_matrix) - true_positive - false_positive - false_negative\n",
        "\n",
        "                sensitivity[i] = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
        "                specificity[i] = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0\n",
        "\n",
        "            sensitivity = np.mean(sensitivity)\n",
        "            specificity = np.mean(specificity)\n",
        "\n",
        "        return sensitivity, specificity\n",
        "\n",
        "    def predict(self, x):\n",
        "        output = self.forward(x)\n",
        "        predictions = np.argmax(output, axis=0)\n",
        "        return predictions\n",
        "\n",
        "    def train(self, x_train, y_train, x_test, y_test, epochs=10,\n",
        "              batch_size=64, l_rate=0.1):\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        num_batches = -(-x_train.shape[0] // self.batch_size)\n",
        "\n",
        "        for i in range(self.epochs):\n",
        "            start_time = time.time()\n",
        "            permutation = np.random.permutation(x_train.shape[0])\n",
        "            x_train_shuffled = x_train[permutation]\n",
        "            y_train_shuffled = y_train[permutation]\n",
        "\n",
        "            for j in range(num_batches):\n",
        "                begin = j * self.batch_size\n",
        "                end = min(begin + self.batch_size, x_train.shape[0]-1)\n",
        "                x = x_train_shuffled[begin:end]\n",
        "                y = y_train_shuffled[begin:end]\n",
        "\n",
        "                output = self.forward(x)\n",
        "                grad = self.backward(y, output)\n",
        "                self.optimize(l_rate=l_rate)\n",
        "\n",
        "            output = self.forward(x_test)\n",
        "            test_acc = self.accuracy(y_test, output)\n",
        "            confusion = self.confusion_matrix(x_test, y_test)\n",
        "            sensitivity, specificity = self.sensitivity_specificity(confusion)\n",
        "\n",
        "            print(f\"Epoch {i+1}: Test accuracy: {test_acc:.4f} \"\n",
        "                  f\"Sensitivity: {sensitivity:.4f} Specificity: {specificity:.4f} \"\n",
        "                  f\"Time: {time.time()-start_time:.2f} sec \")\n",
        "\n",
        "        confusion = self.confusion_matrix(x_test, y_test)\n",
        "        print(\"\")\n",
        "        print(\"Confusion matrix after all epochs:\")\n",
        "        print(\"\")\n",
        "        print(confusion)"
      ],
      "metadata": {
        "id": "zpBA0cvBM9DD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(x, k, dtype=np.float32):\n",
        "    x = np.array(x)\n",
        "    return np.array(x[:, None] == np.arange(k), dtype)"
      ],
      "metadata": {
        "id": "fnz2zaerrCTj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions that allow us to easily visualize the generated images."
      ],
      "metadata": {
        "id": "UhVq_sumai9G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "isEGfzbO1qWn"
      },
      "outputs": [],
      "source": [
        "def show_images(image, num_row=2, num_col=5):\n",
        "    image_size = int(np.sqrt(image.shape[-1]))\n",
        "    image = np.reshape(image, (image.shape[0], image_size, image_size))\n",
        "    fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "    for i in range(num_row*num_col):\n",
        "        ax = axes[i//num_col, i%num_col]\n",
        "        ax.imshow(image[i], cmap='gray', vmin=0, vmax=1)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and normalization of data:\n"
      ],
      "metadata": {
        "id": "jPr5K8K7a37h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "scrolled": true,
        "collapsed": true,
        "id": "_v-pVQKa1qWn"
      },
      "outputs": [],
      "source": [
        "mnist_data = fetch_openml(\"mnist_784\")\n",
        "x = mnist_data[\"data\"]\n",
        "y = mnist_data[\"target\"]\n",
        "\n",
        "x /= 255.0\n",
        "\n",
        "num_labels = 10\n",
        "y_new = one_hot(y.astype('int32'), num_labels)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_new, test_size=0.3, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Qx6vIBflYla_",
        "outputId": "e7e527c0-39b4-4bc1-bf85-624f0797c7a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 750x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's move on to creating a 5-layer neural network with custom activation functions for each layer (specifically, ReLU and sigmoid).\n"
      ],
      "metadata": {
        "id": "w_-8M-3VbxS5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi3RzRkT1qWq",
        "outputId": "e5272c87-3718-4a93-b92f-14d099630cd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Test accuracy: 0.3905 Sensitivity: 0.3798 Specificity: 0.9321 Time: 13.56 sec \n",
            "Epoch 2: Test accuracy: 0.4865 Sensitivity: 0.4778 Specificity: 0.9428 Time: 3.76 sec \n",
            "Epoch 3: Test accuracy: 0.6594 Sensitivity: 0.6551 Specificity: 0.9622 Time: 3.24 sec \n",
            "Epoch 4: Test accuracy: 0.8299 Sensitivity: 0.8272 Specificity: 0.9811 Time: 3.20 sec \n",
            "Epoch 5: Test accuracy: 0.8843 Sensitivity: 0.8831 Specificity: 0.9872 Time: 7.49 sec \n",
            "Epoch 6: Test accuracy: 0.9105 Sensitivity: 0.9100 Specificity: 0.9901 Time: 3.50 sec \n",
            "Epoch 7: Test accuracy: 0.9307 Sensitivity: 0.9301 Specificity: 0.9923 Time: 3.33 sec \n",
            "Epoch 8: Test accuracy: 0.9347 Sensitivity: 0.9344 Specificity: 0.9928 Time: 5.29 sec \n",
            "Epoch 9: Test accuracy: 0.9325 Sensitivity: 0.9322 Specificity: 0.9925 Time: 3.32 sec \n",
            "Epoch 10: Test accuracy: 0.9497 Sensitivity: 0.9494 Specificity: 0.9944 Time: 3.19 sec \n",
            "\n",
            "Confusion matrix after all epochs:\n",
            "\n",
            "[[1993    0    5    2    0    9    7    5    6    0]\n",
            " [   0 2244   11    8    3    0    2    1   27    9]\n",
            " [  12    0 1972   36    1    0   30   14   17    2]\n",
            " [   2    1   29 2078    0   30    2   18   12    2]\n",
            " [   0    8    7    1 1941    3   26   10    3   65]\n",
            " [  16    0    6   61   11 1781   10   10   18    3]\n",
            " [  22    3    6    0    4   21 2005    1    8    0]\n",
            " [   9    3   20   28    3    2    2 2065    6   29]\n",
            " [   0   14   20   30    4   41   23    4 1900   11]\n",
            " [   5    3    2   20   35   16    0   87   14 1964]]\n"
          ]
        }
      ],
      "source": [
        "x_train_values = x_train.values\n",
        "nn = NeuralNetwork([784, 128, 64, 32, 16, 10], activations=['relu', 'sigmoid', 'relu', 'sigmoid', 'relu'])\n",
        "nn.train(x_train_values, y_train, x_test, y_test, batch_size=128, l_rate=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the trained neural network performs excellently.\n"
      ],
      "metadata": {
        "id": "n2mgau49bsSR"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}